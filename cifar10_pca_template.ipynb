{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time \n",
    "start = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cifar10.data_path = \"data/CIFAR-10/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/batches.meta\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = cifar10.load_class_names()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "images_train, cls_train, labels_train = cifar10.load_training_data()\n",
    "images_test, cls_test, labels_test = cifar10.load_test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images_train.shape)\n",
    "#labels_train\n",
    "print(labels_train.shape)\n",
    "\n",
    "print(images_test.shape)\n",
    "#labels_train.shape\n",
    "pred=[]\n",
    "cls_test\n",
    "for i in cls_test:\n",
    "    if i==0:\n",
    "        pred.append(class_names[i])\n",
    "    if i==1:\n",
    "        pred.append(class_names[i])\n",
    "    if i==2:\n",
    "        pred.append(class_names[i])\n",
    "    if i==3:\n",
    "        pred.append(class_names[i])\n",
    "    if i==4:\n",
    "        pred.append(class_names[i])\n",
    "    if i==5:\n",
    "        pred.append(class_names[i])\n",
    "    if i==6:\n",
    "        pred.append(class_names[i])\n",
    "    if i==7:\n",
    "        pred.append(class_names[i])\n",
    "    if i==8:\n",
    "        pred.append(class_names[i])\n",
    "    if i==9:\n",
    "        pred.append(class_names[i])\n",
    "\n",
    "z = np.array(pred)\n",
    "v=pd.DataFrame(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"cifar_pred.csv\",v,fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtr = np.concatenate(images_train)\n",
    "xtr = images_train.reshape(50000,32*32*3)\n",
    "xts = images_test.reshape(10000,3,32, 32)\n",
    "xtts = images_test.reshape(10000,3*32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(xtr.shape)\n",
    "print(xts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3, 32, 32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xttr = xtr\n",
    "xttr.reshape(50000,3,32,32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = svm.SVC(kernel = 'linear')\n",
    "#clf.fit(images_test, cls_test)\n",
    "#Xtr.reshape(50000,32, 32,3)\n",
    "#print(Xtr.reshape(50000,32*32*3))\n",
    "#labels_t = np.concatenate(labels_train)\n",
    "#print(labels_t.shape)\n",
    "#xtr = np.concatenate(Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtr = np.concatenate(Xtr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10 ,whiten=True)\n",
    "transformed_data = pca.fit_transform(xtr)\n",
    "transformed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pca.fit_transform(xtts)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'linear')\n",
    "clf.fit(test_data, cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(test_data, cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10 import img_size , num_channels , num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_size)\n",
    "print(num_channels)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8,8,i+1)\n",
    "    ax.imshow(images_test[i],cmap=plt.cm.bone)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=k ,whiten=True)\n",
    "transformed_data = pca.fit_transform(x)\n",
    "transformed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_val=1000, num_test=10000, show_sample=True):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset, and divide the sample into training set, validation set and test set\n",
    "    \"\"\"\n",
    "\n",
    "    #cifar10_dir = 'datasets/datasets-cifar-10/cifar-10-batches-py/'\n",
    "    #X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    X_train, y_train, X_test, y_test = images_train, labels_train, images_test, labels_test \n",
    "    # subsample the data for validation set\n",
    "    mask = range(num_training, num_training + num_val)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[list(mask)]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def visualize_sample(X_train, y_train, classes, samples_per_class=7):\n",
    "    \"\"\"visualize some samples in the training datasets \"\"\"\n",
    "    num_classes = len(classes)\n",
    "    for y, cls in enumerate(classes):\n",
    "        idxs = np.flatnonzero(y_train == y) # get all the indexes of cls\n",
    "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "        for i, idx in enumerate(idxs): # plot the image one by one\n",
    "            plt_idx = i * num_classes + y + 1 # i*num_classes and y+1 determine the row and column respectively\n",
    "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "            plt.imshow(X_train[idx].astype('uint8'))\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title(cls)\n",
    "    plt.show()\n",
    "    \n",
    "def preprocessing_CIFAR10_data(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1)) # [49000, 3072]\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1)) # [1000, 3072]\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1)) # [10000, 3072]\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    \n",
    "    # Add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))]).T\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))]).T\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))]).T\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above functions to get our data\n",
    "#X_train_raw, y_train_raw, X_val_raw, y_val_raw, X_test_raw, y_test_raw = get_CIFAR10_data()\n",
    "#visualize_sample(X_train_raw, y_train_raw, classes)\n",
    "#X_train, y_train, X_val, y_val, X_test, y_test = preprocessing_CIFAR10_data(X_train_raw, y_train_raw, X_val_raw, y_val_raw, X_test_raw, y_test_raw)\n",
    "\n",
    "# As a sanity check, we print out th size of the training and test data dimenstion\n",
    "#print 'Train data shape: ', X_train.shape\n",
    "#print 'Train labels shape: ', y_train.shape\n",
    "#print 'Validation data shape: ', X_val.shape\n",
    "#print 'Validation labels shape: ', y_val.shape\n",
    "#print 'Test data shape: ', X_test.shape\n",
    "#print 'Test labels shape: ', y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the above functions to get our data\n",
    "X_train_raw, y_train_raw, X_val_raw, y_val_raw, X_test_raw, y_test_raw = get_CIFAR10_data()\n",
    "visualize_sample(X_train_raw, y_train_raw, classes)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = preprocessing_CIFAR10_data(X_train_raw, y_train_raw, X_val_raw, y_val_raw, X_test_raw, y_test_raw)\n",
    "\n",
    "# As a sanity check, we print out th size of the training and test data dimenstion\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[]\n",
    "\n",
    "for j in range(10):\n",
    "    a=[]\n",
    "    for i in range(10):\n",
    "        a.append(i+j)\n",
    "    b.append(a)\n",
    "c=np.concatenate(b)\n",
    "c\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
